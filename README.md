# NLTK Tokenization Example

This repository contains a Python notebook demonstrating the process of tokenization using the Natural Language Toolkit (NLTK) library. Tokenization is the first step in text processing, where text is broken down into smaller units, or tokens, which can be words or sentences.

## Overview

The notebook performs the following steps:

1. **Installation**: Installs the NLTK library for text processing.
2. **Importing Libraries**: Imports necessary functions for tokenization and frequency distribution.
3. **Sample Text**: Provides a paragraph discussing climate change as an example text.
4. **Tokenization**: Uses the `word_tokenize` function to split the text into individual tokens.
5. **Token Count**: Counts the total number of tokens generated from the text.
6. **Frequency Distribution**: Analyzes and displays the frequency of each token using NLTKâ€™s `FreqDist`.

## Requirements

- Python 3.x
- NLTK library

## Usage

1. Clone this repository to your local machine.
2. Open the Jupyter notebook in an environment that has NLTK installed.
3. Run the cells to see how tokenization works.
